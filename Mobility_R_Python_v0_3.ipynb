{"cells":[{"metadata":{"_cell_guid":"a3c61050-dcd2-4cf7-a1b9-1f702b68e74e","collapsed":true,"_uuid":"74e0893f870ff79611b49162a438f9a62fe3e87d","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"4482aa89-2710-42b6-9b34-9c6a0230928a","_uuid":"201340a8e7efaff155f540f1b6bb729bfccc6e17"},"cell_type":"markdown","source":"### What is [BigQuery](https://cloud.google.com/bigquery/what-is-bigquery)??\n\n\nStoring and querying massive datasets can be time consuming and expensive without the right hardware and infrastructure. Google BigQuery is an enterprise data warehouse that solves this problem by enabling super-fast SQL queries using the processing power of Google's infrastructure. Simply move your data into BigQuery and let us handle the hard work. You can control access to both the project and your data based on your business needs, such as giving others the ability to view or query your data.\n\nYou can access BigQuery by using a [web UI ](https://bigquery.cloud.google.com/project/nice-particle-195309)or a [command-line tool](https://cloud.google.com/bigquery/bq-command-line-tool), or by making calls to the BigQuery REST API using a variety of client libraries such as Java, .NET, or Python. There are also a variety of third-party tools that you can use to interact with BigQuery, such as visualizing the data or loading the data.\nBecause the datasets on BigQuery can be very large, there are some restrictions on how much data you can access. \n\n*But You dont need to go to Google, Since Kaggle kernels allows you to access TeraBytes of data from Google cloud with all saftey measures like not letting your query go above memory limits and helper APIs. Thanks to [Sohier](https://www.kaggle.com/sohier)'s [BigQuery helper module](https://github.com/SohierDane/BigQuery_Helper/blob/master/bq_helper.py).\nEach Kaggle user can scan 5TB every 30 days for free.*\n\nLet's first setup environment to run BigQueries in Kaggle Kernels.\n\n### Importing Kaggle's bq_helper package"},{"metadata":{"_cell_guid":"a08640fc-a353-456b-b9a6-d8fdcc11e103","collapsed":true,"_uuid":"40a811126d0b55dee969c5340107592f8e4c8a34","trusted":true},"cell_type":"code","source":"import bq_helper ","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"9b6ad429-c606-4738-827c-2b08cc9ec70a","_uuid":"9b5f26f40dad9097966b335654b72c9d80ae3570"},"cell_type":"markdown","source":"### Creating a helper object for  bigquery dataset\n\nThe addresses of BigQuery datasets look like this![](https://i.imgur.com/l11gdKx.png)\n\nfor us dataset is **github_repos**\n\n[Rachael](https://www.kaggle.com/rtatman) from Kaggle has ran a 5 days BigQuery Introductory challenge called SQL Scavenger Hunt. We will go through day 1 to 5 using Github Repos Dataset.\n\nImage is taken from [SQL Scavenger Handbook](https://www.kaggle.com/rtatman/sql-scavenger-hunt-handbook)"},{"metadata":{},"cell_type":"markdown","source":"In this case we are going to derive data from the monthy github archive datasets"},{"metadata":{"_cell_guid":"48321d8d-51eb-416b-9f0c-034010ef0cd2","collapsed":true,"_uuid":"391415119f4c33697ff0ea72b6f74a7d8d97d79b","trusted":true},"cell_type":"code","source":"github_archive = bq_helper.BigQueryHelper(active_project= \"githubarchive\", \n                                       dataset_name = \"month\")\n\ngithub_archive_day = bq_helper.BigQueryHelper(active_project= \"githubarchive\", \n                                       dataset_name = \"day\")","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"26bf2aa8-3268-4b8f-b2f7-cfabbf82731b","_uuid":"f986ecd7fbe923e1ce95c0b475ded457032f60d7"},"cell_type":"markdown","source":"### Listing Tables"},{"metadata":{"_cell_guid":"79b2227f-093e-4ff7-b288-e087e6ec3187","_uuid":"0de298b23d3282200e9ba1ffb20ddb93b6f5169a","trusted":true},"cell_type":"code","source":"# print a list of all the tables in the github archive dataset\ngithub_archive.list_tables()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"['201102',\n '201103',\n '201104',\n '201105',\n '201106',\n '201107',\n '201108',\n '201109',\n '201110',\n '201111',\n '201112',\n '201201',\n '201202',\n '201203',\n '201204',\n '201205',\n '201206',\n '201207',\n '201208',\n '201209',\n '201210',\n '201211',\n '201212',\n '201301',\n '201302',\n '201303',\n '201304',\n '201305',\n '201306',\n '201307',\n '201308',\n '201309',\n '201310',\n '201311',\n '201312',\n '201401',\n '201402',\n '201403',\n '201404',\n '201405',\n '201406',\n '201407',\n '201408',\n '201409',\n '201410',\n '201411',\n '201412',\n '201501',\n '201502',\n '201503',\n '201504',\n '201505',\n '201506',\n '201507',\n '201508',\n '201509',\n '201510',\n '201511',\n '201512',\n '201601',\n '201602',\n '201603',\n '201604',\n '201605',\n '201606',\n '201607',\n '201608',\n '201609',\n '201610',\n '201611',\n '201612',\n '201701',\n '201702',\n '201703',\n '201704',\n '201705',\n '201706',\n '201707',\n '201708',\n '201709',\n '201710',\n '201711',\n '201712',\n '201801',\n '201802',\n '201803',\n '201804',\n '201805',\n '201806',\n '201807',\n '201808',\n '201809',\n '201810',\n '201811',\n '201812',\n '201901',\n '201902',\n '201903',\n '201904',\n '201905',\n '201906',\n '201907',\n '201908',\n '201909',\n '201910',\n '201911',\n '201912',\n '202001',\n '202002',\n '202003',\n '202004']"},"metadata":{}}]},{"metadata":{"_cell_guid":"bad84731-af9f-4457-bead-75f7ea2ec940","_uuid":"f673434ae44c61970f02ac3de06c93bd7e3a242b"},"cell_type":"markdown","source":"###  Printing Table Schema\n"},{"metadata":{"_cell_guid":"e9b9bbfd-af09-45e8-8d9a-c7b089752f0f","_uuid":"e3f038704629150caf10e59a0acf65c6b2a130b9","trusted":true},"cell_type":"code","source":"# print information on all the columns in the september 2015 dataset\n# in the github_archive dataset\ngithub_archive.table_schema(\"201509\")","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"[SchemaField('type', 'string', 'NULLABLE', None, ()),\n SchemaField('public', 'boolean', 'NULLABLE', None, ()),\n SchemaField('payload', 'string', 'NULLABLE', None, ()),\n SchemaField('repo', 'record', 'NULLABLE', None, (SchemaField('id', 'integer', 'NULLABLE', None, ()), SchemaField('name', 'string', 'NULLABLE', None, ()), SchemaField('url', 'string', 'NULLABLE', None, ()))),\n SchemaField('actor', 'record', 'NULLABLE', None, (SchemaField('id', 'integer', 'NULLABLE', None, ()), SchemaField('login', 'string', 'NULLABLE', None, ()), SchemaField('gravatar_id', 'string', 'NULLABLE', None, ()), SchemaField('avatar_url', 'string', 'NULLABLE', None, ()), SchemaField('url', 'string', 'NULLABLE', None, ()))),\n SchemaField('org', 'record', 'NULLABLE', None, (SchemaField('id', 'integer', 'NULLABLE', None, ()), SchemaField('login', 'string', 'NULLABLE', None, ()), SchemaField('gravatar_id', 'string', 'NULLABLE', None, ()), SchemaField('avatar_url', 'string', 'NULLABLE', None, ()), SchemaField('url', 'string', 'NULLABLE', None, ()))),\n SchemaField('created_at', 'timestamp', 'NULLABLE', None, ()),\n SchemaField('id', 'string', 'NULLABLE', None, ()),\n SchemaField('other', 'string', 'NULLABLE', None, ())]"},"metadata":{}}]},{"metadata":{"_cell_guid":"b9639c61-4f93-4ba1-ad9d-c12c7b173e61","_uuid":"576cc3603299b399800004fa71f06ba5ab9ab056","scrolled":true,"trusted":true},"cell_type":"code","source":"# preview the first couple lines of the table\ngithub_archive.head(\"201509\")","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"        type  public                                            payload  \\\n0  ForkEvent    True  {\"forkee\":{\"id\":42360666,\"name\":\"RepData_PeerA...   \n1  ForkEvent    True  {\"forkee\":{\"id\":42763297,\"name\":\"StudyDemo\",\"f...   \n2  ForkEvent    True  {\"forkee\":{\"id\":41809728,\"name\":\"crypto_tutori...   \n3  ForkEvent    True  {\"forkee\":{\"id\":41995755,\"name\":\"CodeForces\",\"...   \n4  ForkEvent    True  {\"forkee\":{\"id\":42421484,\"name\":\"scripts\",\"ful...   \n\n                                                repo  \\\n0  {'id': 16709733, 'name': 'rdpeng/RepData_PeerA...   \n1  {'id': 7349143, 'name': 'feicien/StudyDemo', '...   \n2  {'id': 41669127, 'name': 'joearms/crypto_tutor...   \n3  {'id': 11129094, 'name': 'fuwutu/CodeForces', ...   \n4  {'id': 13257697, 'name': 'leleobhz/scripts', '...   \n\n                                               actor  \\\n0  {'id': 3484977, 'login': 'mosm', 'gravatar_id'...   \n1  {'id': 5559075, 'login': 'ygq1991', 'gravatar_...   \n2  {'id': 7746127, 'login': 'ado-ua', 'gravatar_i...   \n3  {'id': 11884005, 'login': 'dumubuchenglin', 'g...   \n4  {'id': 2694108, 'login': 'Fransalcas', 'gravat...   \n\n                                                 org  \\\n0  {'id': None, 'login': None, 'gravatar_id': Non...   \n1  {'id': None, 'login': None, 'gravatar_id': Non...   \n2  {'id': None, 'login': None, 'gravatar_id': Non...   \n3  {'id': None, 'login': None, 'gravatar_id': Non...   \n4  {'id': None, 'login': None, 'gravatar_id': Non...   \n\n                 created_at          id other  \n0 2015-09-12 14:53:23+00:00  3141379118  None  \n1 2015-09-19 06:58:25+00:00  3162340524  None  \n2 2015-09-02 15:33:48+00:00  3111932382  None  \n3 2015-09-06 08:55:41+00:00  3122147909  None  \n4 2015-09-14 02:03:43+00:00  3143044884  None  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>public</th>\n      <th>payload</th>\n      <th>repo</th>\n      <th>actor</th>\n      <th>org</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ForkEvent</td>\n      <td>True</td>\n      <td>{\"forkee\":{\"id\":42360666,\"name\":\"RepData_PeerA...</td>\n      <td>{'id': 16709733, 'name': 'rdpeng/RepData_PeerA...</td>\n      <td>{'id': 3484977, 'login': 'mosm', 'gravatar_id'...</td>\n      <td>{'id': None, 'login': None, 'gravatar_id': Non...</td>\n      <td>2015-09-12 14:53:23+00:00</td>\n      <td>3141379118</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ForkEvent</td>\n      <td>True</td>\n      <td>{\"forkee\":{\"id\":42763297,\"name\":\"StudyDemo\",\"f...</td>\n      <td>{'id': 7349143, 'name': 'feicien/StudyDemo', '...</td>\n      <td>{'id': 5559075, 'login': 'ygq1991', 'gravatar_...</td>\n      <td>{'id': None, 'login': None, 'gravatar_id': Non...</td>\n      <td>2015-09-19 06:58:25+00:00</td>\n      <td>3162340524</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ForkEvent</td>\n      <td>True</td>\n      <td>{\"forkee\":{\"id\":41809728,\"name\":\"crypto_tutori...</td>\n      <td>{'id': 41669127, 'name': 'joearms/crypto_tutor...</td>\n      <td>{'id': 7746127, 'login': 'ado-ua', 'gravatar_i...</td>\n      <td>{'id': None, 'login': None, 'gravatar_id': Non...</td>\n      <td>2015-09-02 15:33:48+00:00</td>\n      <td>3111932382</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ForkEvent</td>\n      <td>True</td>\n      <td>{\"forkee\":{\"id\":41995755,\"name\":\"CodeForces\",\"...</td>\n      <td>{'id': 11129094, 'name': 'fuwutu/CodeForces', ...</td>\n      <td>{'id': 11884005, 'login': 'dumubuchenglin', 'g...</td>\n      <td>{'id': None, 'login': None, 'gravatar_id': Non...</td>\n      <td>2015-09-06 08:55:41+00:00</td>\n      <td>3122147909</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ForkEvent</td>\n      <td>True</td>\n      <td>{\"forkee\":{\"id\":42421484,\"name\":\"scripts\",\"ful...</td>\n      <td>{'id': 13257697, 'name': 'leleobhz/scripts', '...</td>\n      <td>{'id': 2694108, 'login': 'Fransalcas', 'gravat...</td>\n      <td>{'id': None, 'login': None, 'gravatar_id': Non...</td>\n      <td>2015-09-14 02:03:43+00:00</td>\n      <td>3143044884</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"9405a457-c3d3-491a-a808-f5fbec1e565a","_uuid":"0ed5b991e041fb8f795f1f18e6c9dc6346c85c7a"},"cell_type":"markdown","source":"### Checking the size of our query before we run it\n\n\n\nOur Dataset is quite large so we can easily cross tha monthly limit by running few queries. \n\nWe should always estimate  how much data we need to scan for executing this query by **BigQueryHelper.estimate_query_size()** method.\n"},{"metadata":{"_cell_guid":"2ad9394e-d741-44c2-9e23-c27486a291a6","_uuid":"5b22e98e2655624c4c4714e3e12d51e7a7df9ec9","scrolled":false,"trusted":true,"collapsed":true},"cell_type":"code","source":"query_pulls= \"\"\"SELECT\n            repo,\n            type,\n            actor,\n            payload\n            FROM `githubarchive.month.201509`\n            WHERE type = 'PullRequestEvent'\n        \"\"\"\n\nquery_pulls_user= \"\"\"SELECT\n            repo.name as repo_name,\n            JSON_EXTRACT(payload, '$.pull_request.user.login') as user,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') as language\n            FROM `githubarchive.day.20150901`\n            WHERE type = 'PullRequestEvent'\n            LIMIT 1000\n        \"\"\"\n\n\nquery_pulls_user= \"\"\"SELECT\n            repo.name as repo_name,\n            JSON_EXTRACT(payload, '$.pull_request.user.login') as user,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') as language,\n            JSON_EXTRACT(payload, '$.action') as action\n            FROM `githubarchive.day.20150901`\n            WHERE type = 'PullRequestEvent'\n            LIMIT 1000\n        \"\"\"\n\ngithub_archive.estimate_query_size(query_pulls_user)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"github_repo_pull = github_archive.query_to_pandas_safe(query_pulls_user, max_gb_scanned=2)\ngithub_repo_pull.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"github_repo_pull.to_csv('github_repo_pull_20150901_.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"query1= \"\"\"SELECT\n            repo,\n            JSON_EXTRACT(payload, '$.pull_request.user.login') as puller,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') as language\n            FROM `githubarchive.month.201501`\n            WHERE type = 'PullRequestEvent' AND JSON_EXTRACT(payload, '$.action.repo.language')\n         \"\"\"\n\nquery_pulls_user= \"\"\"SELECT\n            repo.name as repo_name,\n            JSON_EXTRACT(payload, '$.pull_request.user.login') as user,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') as language\n            FROM `githubarchive.month.201501`\n            WHERE type = 'PullRequestEvent'\n        \"\"\"\n\nquery_pulls_user_grouped= \"\"\"SELECT\n            JSON_EXTRACT(payload, '$.pull_request.user.login') AS user,\n            repo.name AS repo_name,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') AS language,\n            COUNT(*) AS number_actions\n            FROM `githubarchive.day.20150901`\n            WHERE type = 'PullRequestEvent'\n            GROUP BY repo_name, user, language\n        \"\"\"\n\n# Where clause not working, dont know why\nquery_pulls_user_grouped_opened= \"\"\"SELECT\n            JSON_EXTRACT(payload, '$.pull_request.user.login') AS user,\n            repo.name AS repo_name,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') AS language,\n            COUNT(*) AS number_actions\n            FROM `githubarchive.day.20150901`\n            WHERE ((type = 'PullRequestEvent') AND (JSON_EXTRACT(payload, '$.action') = 'opened'))\n            GROUP BY repo_name, user, language\n        \"\"\"\n\n# This is the definitive query\nquery_pulls_user_grouped= \"\"\"SELECT\n            JSON_EXTRACT(payload, '$.pull_request.user.login') AS user,\n            repo.name AS repo_name,\n            JSON_EXTRACT(payload, '$.pull_request.base.repo.language') AS language,\n            JSON_EXTRACT(payload, '$.action') AS action,\n            JSON_EXTRACT(payload, '$.pull_request.merged') AS merged,\n            COUNT(*) AS number_actions\n            FROM `githubarchive.day.20150901`\n            WHERE type = 'PullRequestEvent'\n            GROUP BY repo_name, user, language, action, merged\n        \"\"\"\n\n\n\ngithub_archive_day.estimate_query_size(query_pulls_user_grouped)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7446e159-5be5-4f85-96eb-5ba975588cc8","_uuid":"11c94ec2dd2072a81fca0fd7a8ac518ff34956de"},"cell_type":"markdown","source":"Now I will use the query to pandas function to make the query of the dayly dataframe as a test"},{"metadata":{"_cell_guid":"32b9aade-97a3-4a9a-abc5-1f904124dfab","_uuid":"560a098c6597a931b526a56240ae34592575dda7","trusted":true,"collapsed":true},"cell_type":"code","source":"github_user_pulls = github_archive_day.query_to_pandas_safe(query_pulls_user_grouped, max_gb_scanned=2)\ngithub_user_pulls.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"github_user_pulls.to_csv('github_user_pull_20150901_actions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5d85fea1-8a1a-4edb-918f-76a56beb701e","_uuid":"e74b08fa0b2ae15527144d65efd48ddd1d7c0f41"},"cell_type":"markdown","source":"Now I want to make a for loop that changes the query, extracting data from month to month during an specific year\n"},{"metadata":{"_cell_guid":"260bebd2-d92f-4963-89b9-f8e70a9380f1","_uuid":"6a5e5e5894d073ba3d77db0f920b6a8c79c70430","trusted":true},"cell_type":"code","source":"query_year = \"2019\"\n#query_month = \"01\"\n\n#Array with the months of the year\nmonths_array = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\",\"08\", \"09\", \"10\", \"11\",\"12\"]\n\n#months_array = [\"01\", \"02\",\"03\"]\n                \nfor query_month in months_array:\n    \n    # Print the year and month\n    print(\"year = \" + query_year + \", month = \" + query_month)\n    \n    # Query for the extraction of the number of pull actions in the dataframe\n    query_pulls_user_grouped= \"\"\"SELECT\n                JSON_EXTRACT(payload, '$.pull_request.user.login') AS user,\n                repo.name AS repo_name,\n                JSON_EXTRACT(payload, '$.pull_request.base.repo.language') AS language,\n                JSON_EXTRACT(payload, '$.action') AS action,\n                JSON_EXTRACT(payload, '$.pull_request.merged') AS merged,\n                COUNT(*) AS number_actions\n                FROM `githubarchive.month.{year}{month}`\n                WHERE type = 'PullRequestEvent'\n                GROUP BY repo_name, user, language, action, merged\n            \"\"\".format(year= query_year,month=query_month)\n    \n    #github_archive.estimate_query_size(query_pulls_user_grouped)\n    \n    # Executes the query, it will not work if more than 70 gb are scanned\n    github_user_pulls = github_archive.query_to_pandas_safe(query_pulls_user_grouped, max_gb_scanned=250)\n    \n    #Writes the csv\n    github_user_pulls.to_csv(\"github_user_pull_count_\" + query_year + query_month + \".csv\",index=False)\n    \n    print(\"Ready!\")\n    \n#github_user_pulls\n\n#github_user_pulls.to_csv('github_user_pull_ + 20150901_actions.csv',index=False)\n\n#github_archive.estimate_query_size(query_pulls_user_grouped)","execution_count":11,"outputs":[{"output_type":"stream","text":"year = 2020, month = 01\nReady!\nyear = 2020, month = 02\nReady!\nyear = 2020, month = 03\n","name":"stdout"},{"output_type":"error","ename":"TooManyRequests","evalue":"429 GET https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/datasets/_6dad5c6311d75279e22694346589feaea582ecd9/tables/anonadab1e974a31410762632a0b9bce29b2f04fd040/data?selectedFields=user%2Crepo_name%2Clanguage%2Caction%2Cmerged%2Cnumber_actions: Quota exceeded","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5f1ffc4b66ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Executes the query, it will not work if more than 70 gb are scanned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mgithub_user_pulls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgithub_archive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_to_pandas_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_pulls_user_grouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_gb_scanned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#Writes the csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/src/bq-helper/bq_helper.py\u001b[0m in \u001b[0;36mquery_to_pandas_safe\u001b[0;34m(self, query, max_gb_scanned)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mquery_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_query_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_gb_scanned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_to_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Query cancelled; estimated size of {query_size} exceeds limit of {max_gb_scanned} GB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/src/bq-helper/bq_helper.py\u001b[0m in \u001b[0;36mquery_to_pandas\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[1;32m     77\u001b[0m         \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         return pd.DataFrame(\n\u001b[1;32m     80\u001b[0m             data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/page_iterator.py\u001b[0m in \u001b[0;36m_items_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_items_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Iterator for each item returned.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_page_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_results\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/page_iterator.py\u001b[0m in \u001b[0;36m_page_iter\u001b[0;34m(self, increment)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mPage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meach\u001b[0m \u001b[0mpage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \"\"\"\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/page_iterator.py\u001b[0m in \u001b[0;36m_next_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_next_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_page_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_to_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/page_iterator.py\u001b[0m in \u001b[0;36m_get_next_page_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_HTTP_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 query_params=params)\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_HTTP_METHOD\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'POST'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             return self.api_request(\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             )\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTooManyRequests\u001b[0m: 429 GET https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/datasets/_6dad5c6311d75279e22694346589feaea582ecd9/tables/anonadab1e974a31410762632a0b9bce29b2f04fd040/data?selectedFields=user%2Crepo_name%2Clanguage%2Caction%2Cmerged%2Cnumber_actions: Quota exceeded"]}]},{"metadata":{"_cell_guid":"83d2c5cc-e162-444b-9418-1ac37235a214","_uuid":"031664196408266c7f862a0b2b8f472dbd9d1147","trusted":true,"collapsed":true},"cell_type":"code","source":"query_year = \"2015\"\nquery_month = \"01\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"60f53bfe-c8e4-4aca-8755-3b6b69433103","_uuid":"9c76de7d409bc99f1c89b277e2f7c8f39aca9aca"},"cell_type":"markdown","source":"### How many github repositories are in form of binary files?\nA binary file is a file stored in binary format. A binary file is computer-readable but not human-readable. All executable programs are stored in binary files, as are most numeric data files."},{"metadata":{"_cell_guid":"b785396e-8aa2-482f-ab69-6001a8522402","_uuid":"5e10911ad48c25cd8415c2855dec7dbc8cafd4db","trusted":true,"collapsed":true},"cell_type":"code","source":"#%%time\n#query2= \"\"\"SELECT binary\n#            FROM `bigquery-public-data.github_repos.contents`\n#            LIMIT 50000\n#        \"\"\"\n#\n#binary_files=github_repos.query_to_pandas_safe(query2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","pygments_lexer":"ipython3","name":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}